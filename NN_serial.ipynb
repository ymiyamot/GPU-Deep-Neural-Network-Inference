{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This script does deep neural network inference without parallelization\n",
    "# for comparing speed and correctness\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decide the parameters of the structure of the neural network\n",
    "n_layers = 4 # Including input and output layer\n",
    "n_classes = 2 # Size of output layer\n",
    "n_neurons = [2**8, 2**8, 2**8, n_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate weights\n",
    "weights = []\n",
    "for layer_i in range(n_layers - 1):\n",
    "    n_pre_layer = n_neurons[layer_i]\n",
    "    n_post_layer = n_neurons[layer_i + 1]\n",
    "    weights.append(np.random.normal(size=(n_post_layer, n_pre_layer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate inputs\n",
    "n_inputs = 3\n",
    "inputs = np.random.normal(size=(n_neurons[0], n_inputs)) # random inputs\n",
    "# inputs = np.zeros(shape=(n_neurons[0], n_inputs)) # zero inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate nonlinear activation function\n",
    "def nonlin_activation(x):\n",
    "    return 2 * np.exp(x) / (np.exp(x) + 1) - 1\n",
    "\n",
    "def softmax(x):\n",
    "    out = np.zeros_like(x)\n",
    "    for colm_i in range(x.shape[1]):        \n",
    "        exp_elem = np.exp(x[:, colm_i])\n",
    "        out[:, colm_i] = exp_elem / np.sum(exp_elem)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Propagate inputs through network\n",
    "def infer_np_serial(inputs):\n",
    "    layer_inputs = inputs\n",
    "    for layer_i in range(n_layers - 1):\n",
    "        if layer_i != n_layers - 2:\n",
    "            layer_inputs = nonlin_activation(weights[layer_i].dot(layer_inputs))\n",
    "        else:\n",
    "            layer_inputs = softmax(weights[layer_i].dot(layer_inputs))\n",
    "            output = layer_inputs\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(256, 256), (256, 256), (2, 256)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aa826517b93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Yohlo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/numpy/lib/shape_base.pyc\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_replace_zero_by_x_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "np.dstack(weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load run_NNs.py\n",
    "from __future__ import division\n",
    "import sys\n",
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "\n",
    "import NN_serial\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# List our platforms\n",
    "platforms = cl.get_platforms()\n",
    "print 'The platforms detected are:'\n",
    "print '---------------------------'\n",
    "for platform in platforms:\n",
    "    print platform.name, platform.vendor, 'version:', platform.version\n",
    "\n",
    "# List devices in each platform\n",
    "for platform in platforms:\n",
    "    print 'The devices detected on platform', platform.name, 'are:'\n",
    "    print '---------------------------'\n",
    "    for device in platform.get_devices():\n",
    "        print device.name, '[Type:', cl.device_type.to_string(device.type), ']'\n",
    "        print 'Maximum clock Frequency:', device.max_clock_frequency, 'MHz'\n",
    "        print 'Maximum allocable memory size:', int(device.max_mem_alloc_size / 1e6), 'MB'\n",
    "        print 'Maximum work group size', device.max_work_group_size\n",
    "        print '---------------------------'\n",
    "\n",
    "# Create a context with all the devices\n",
    "devices = platforms[0].get_devices()\n",
    "context = cl.Context([devices[2]])\n",
    "print 'This context is associated with ', len(context.devices), 'devices'\n",
    "\n",
    "# Create a queue for transferring data and launching computations.\n",
    "# Turn on profiling to allow us to check event times.\n",
    "queue = cl.CommandQueue(context, context.devices[0],\n",
    "                        properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "print 'The queue is using the device:', queue.device.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Set up neural network parameters ###\n",
    "# Decide the parameters of the structure of the neural network\n",
    "n_layers = 4 # Including input and output layer\n",
    "n_classes = 2 # Size of output layer\n",
    "n_neurons = [2**8, 2**8, 2**8, n_classes]\n",
    "n_neurons = [3, 3, 3, n_classes]\n",
    "\n",
    "# Generate weights\n",
    "weights = []\n",
    "for layer_i in range(n_layers - 1):\n",
    "    n_pre_layer = n_neurons[layer_i]\n",
    "    n_post_layer = n_neurons[layer_i + 1]\n",
    "    weights.append(np.random.normal(size=(n_post_layer, n_pre_layer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_1d = np.hstack([x.flatten() for x in weights])\n",
    "inputs_1d = inputs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate inputs\n",
    "n_inputs = 3\n",
    "inputs = np.random.normal(size=(n_neurons[0], n_inputs)) # random inputs\n",
    "# inputs = np.zeros(shape=(n_neurons[0], n_inputs)) # zero inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8801707 ,  1.1783842 , -0.11314505],\n",
       "       [-1.62698477, -0.18739597, -0.8429538 ],\n",
       "       [ 0.97693783,  0.84947339, -0.40892578]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_serial = NN_serial.infer_np_serial(inputs,\n",
    "                                weights,\n",
    "                                n_layers,\n",
    "                                n_classes,\n",
    "                                n_neurons)\n",
    "print(output_serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The platforms detected are:\n",
      "---------------------------\n",
      "Apple Apple version: OpenCL 1.2 (Sep 20 2014 22:01:02)\n",
      "The devices detected on platform Apple are:\n",
      "---------------------------\n",
      "Intel(R) Core(TM) i7-3615QM CPU @ 2.30GHz [Type: CPU ]\n",
      "Maximum clock Frequency: 2300 MHz\n",
      "Maximum allocable memory size: 4294 MB\n",
      "Maximum work group size 1024\n",
      "---------------------------\n",
      "HD Graphics 4000 [Type: GPU ]\n",
      "Maximum clock Frequency: 1200 MHz\n",
      "Maximum allocable memory size: 268 MB\n",
      "Maximum work group size 512\n",
      "---------------------------\n",
      "GeForce GT 650M [Type: GPU ]\n",
      "Maximum clock Frequency: 900 MHz\n",
      "Maximum allocable memory size: 268 MB\n",
      "Maximum work group size 1024\n",
      "---------------------------\n",
      "This context is associated with  1 devices\n",
      "The queue is using the device: GeForce GT 650M\n",
      "[[  9.99999537e-01   9.99999939e-01   5.81488874e-05]\n",
      " [  4.63442444e-07   6.09749243e-08   9.99941851e-01]]\n"
     ]
    }
   ],
   "source": [
    "output_serial = NN_serial.infer_np_serial(inputs,\n",
    "                                weights,\n",
    "                                n_layers,\n",
    "                                n_classes,\n",
    "                                n_neurons)\n",
    "print(output_serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    program = cl.Program(context, open('label_regions.cl').read()).build(options='')\n",
    "#\n",
    "#    host_image = np.load('maze2.npy')\n",
    "#    host_labels = np.empty_like(host_image)\n",
    "#    host_done_flag = np.zeros(1).astype(np.int32)\n",
    "#\n",
    "#    gpu_image = cl.Buffer(context, cl.mem_flags.READ_ONLY, host_image.size * 4)\n",
    "#    gpu_labels = cl.Buffer(context, cl.mem_flags.READ_WRITE, host_image.size * 4)\n",
    "#    gpu_done_flag = cl.Buffer(context, cl.mem_flags.READ_WRITE, 4)\n",
    "#\n",
    "#    # Send to the device, non-blocking\n",
    "#    cl.enqueue_copy(queue, gpu_image, host_image, is_blocking=False)\n",
    "#\n",
    "#    local_size = (8, 8)  # 64 pixels per work group\n",
    "#    global_size = tuple([round_up(g, l) for g, l in zip(host_image.shape[::-1], local_size)])\n",
    "#    print global_size\n",
    "#    width = np.int32(host_image.shape[1])\n",
    "#    height = np.int32(host_image.shape[0])\n",
    "#    halo = np.int32(1)\n",
    "#\n",
    "#    # Create a local memory per working group that is\n",
    "#    # the size of an int (4 bytes) * (N+2) * (N+2), where N is the local_size\n",
    "#    buf_size = (np.int32(local_size[0] + 2 * halo), np.int32(local_size[1] + 2 * halo))\n",
    "#    gpu_local_memory = cl.LocalMemory(4 * buf_size[0] * buf_size[1])\n",
    "#\n",
    "#    # initialize labels\n",
    "#    program.initialize_labels(queue, global_size, local_size,\n",
    "#                              gpu_image, gpu_labels,\n",
    "#                              width, height)\n",
    "#\n",
    "#    # while not done, propagate labels\n",
    "#    itercount = 0\n",
    "#\n",
    "#    # Show the initial labels\n",
    "#    cl.enqueue_copy(queue, host_labels, gpu_labels, is_blocking=True)\n",
    "#    pylab.imshow(host_labels)\n",
    "#    pylab.title(itercount)\n",
    "#    pylab.colorbar()\n",
    "#    pylab.show()\n",
    "#\n",
    "##    cl.enqueue_copy(queue, gpu_done_flag, host_done_flag, is_blocking=False)\n",
    "##    prop_exec = program.propagate_labels(queue, global_size, local_size,\n",
    "##                                             gpu_labels, gpu_done_flag,\n",
    "##                                             gpu_local_memory,\n",
    "##                                             width, height,\n",
    "##                                             buf_size[0], buf_size[1],\n",
    "##                                             halo)\n",
    "#\n",
    "#    show_progress = True\n",
    "#    total_time = 0\n",
    "#\n",
    "#    while True:\n",
    "#        itercount += 1\n",
    "#        host_done_flag[0] = 0\n",
    "#        print 'iter', itercount\n",
    "#        cl.enqueue_copy(queue, gpu_done_flag, host_done_flag, is_blocking=False)\n",
    "#        prop_exec = program.propagate_labels(queue, global_size, local_size,\n",
    "#                                             gpu_labels, gpu_done_flag,\n",
    "#                                             gpu_local_memory,\n",
    "#                                             width, height,\n",
    "#                                             buf_size[0], buf_size[1],\n",
    "#                                             halo)\n",
    "#        prop_exec.wait()\n",
    "#        elapsed = 1e-6 * (prop_exec.profile.end - prop_exec.profile.start)\n",
    "#        total_time += elapsed\n",
    "#        # read back done flag, block until it gets here\n",
    "#        cl.enqueue_copy(queue, host_done_flag, gpu_done_flag, is_blocking=True)\n",
    "#        if host_done_flag[0] == 0:\n",
    "#            # no changes\n",
    "#            break\n",
    "#        # there were changes, so continue running\n",
    "#        print host_done_flag\n",
    "#        if itercount % 100 == 0 and show_progress:\n",
    "#            cl.enqueue_copy(queue, host_labels, gpu_labels, is_blocking=True)\n",
    "#            pylab.imshow(host_labels)\n",
    "#            pylab.title(itercount)\n",
    "#            pylab.show()\n",
    "#        if itercount % 10000 == 0:\n",
    "#            print 'Reached maximal number of iterations, aborting'\n",
    "#            sys.exit(0)\n",
    "#\n",
    "#    print('Finished after {} iterations, {} ms total, {} ms per iteration'.format(itercount, total_time, total_time / itercount))\n",
    "#    # Show final result\n",
    "#    cl.enqueue_copy(queue, host_labels, gpu_labels, is_blocking=True)\n",
    "#    print 'Found {} regions'.format(len(np.unique(host_labels)) - 1)\n",
    "#    pylab.imshow(host_labels)\n",
    "#    pylab.title(itercount)\n",
    "#    pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
